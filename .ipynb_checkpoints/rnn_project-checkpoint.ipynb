{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Final project PHP code Hila Tashtash&Reut Maza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Rnn Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to work with php code, which was the language code we used in our final project.\n",
    "because our final project was only 6,000 code lines and it wasn't enough to get results we increase our data by adding php code from open source projects from this site: https://github.com/trending/php.  \n",
    "The purpous of this exercise will be to build a Language Model using a Recurrent Neural Network, A language model allows us to predict the probability of observing the sentence and produce new sequences using the model being studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description: Description of data collection chosen, are the main challenges of working with this data? Why study interesting and where he can contribute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned we chose php code as our data. The chanllanges were to arrange the data , we had to thought what is the start and the end of sentence in our data, not as regular data which start is the start of the sentence and the end is the end of the sentence, in our case it wasn't so clear what is the start and the end. we tried 2 different attuides, the start will be at the start of single raw code and the same the end. for example: START print(\"hello\"); END , the second attuide was that the start is the start of block of code and the end is the end of the block, for example: START <?php\n",
    "namespace Spatie\\Regex;\n",
    "abstract class RegexResult\n",
    "{\n",
    "    protected static function lastPregError(): string\n",
    "    {\n",
    "        return array_flip(get_defined_constants(true)['pcre'])[preg_last_error()];\n",
    "    }\n",
    "}\n",
    "?>\n",
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got in the first attuide the following generated sentences:\n",
    "\n",
    "SENTENCE_START one raw code SENTENCE_END\n",
    "\n",
    "\n",
    "1. . mimeType |n50 PasswordResetModel : SENTENCE_START\n",
    "\n",
    "2. print_r writeHttp rating=\\ Value b'Cache SENTENCE_START\n",
    "\n",
    "3. of 's 'size hail chan & name returnInfo skey return provider SENTENCE_START\n",
    "\n",
    "4. a 60 w++ \\'array\\ //php.net/manual/en/function.stream-set-timeout.php ( 'array instantly SENTENCE_START :\n",
    "\n",
    "5. a print_r handling __destruct :getKeywordSuggestionsFromGoogle \\\\count SENTENCE_START\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second attuide we got the following generated sentences:\n",
    "\n",
    "BLOCK_START one raw code BLOCK_END\n",
    "\n",
    "1. 'script-src color for ) kamisama.me ( ) ) self ) return ( ) validateUserName SD ( ) effect for ) ( ) A preg_match_all ( ) j it ) ( ) )\n",
    "\n",
    "2. project-specific encodedString room var then strict_types=1 return ) ' color ( ) BLOCK_START_hour myWordsArray Optional Decode ( ) like public int 'twelve ( ) ) user_password_reset_hash includeQuery ( ) ) ( ) Symfony\\Component\\Config ( ) # avaliable 5MB max_release_Lecturer for ) ( ) ) ) this We index_i ( ) getMessage ) ( ) ) ( ) for for ) ( ) ) would ( ) phar- : .= docid ( ) j compute ) optionally ( ) ) 'routes for ) ) changePassword creating i return ) sql ( ) FILTER_FLAG_IPV4 Filter ( ) replacement i++ ( ) throw query- ' VALUES for ) Check file time ( ) password '/manifest.json return ) ( ) // be configuration ( ) ) getMessage ( ) updateChannel ( ) ) ^\\/ server ( ) argc ( ) group password ) for ) i++ throws - mixed . ( ) ( ) getMessage ) ( ) ) ( ) ) ) BY self ) for return ) row for self ) \\is_dir self return ) ( & ) password ) ' `` parking_slot_number directory ( ) ) for ) ) ( ) Cache name result json_decode ( ) j value i airship_files i value i 'resource ) priority ( ) \\Airship\\get_database uniqueid [ ; :encode self ) secondsToText ) j return ( ) ) AMQPChannel of i=1 self self return ) ( ) swiftmailer for ) ( ) if for self ) str ' queryString '/ ] \\n the ( & return ) Client|Manager i lookup ) extraName ) database ( ) ) ( ) ) ( ) :getPublicAvatarFilePathOfUser ) Database ( ) ) ( ) ( ) i words ) 'day_ ) State ; php files this- fraction =0 case ( ) ( ) j hasRecordThatPasses for ) ( ) & ( ) ) ( ) ) for ) attributes parking ( ) ) first context ) : ; source do ] 'feedback_negative /** { ( ) ) for ) ( ) 'Content-type password ) ( ) ) ( ) ) return ( ) ) ( ) INSERT ( ) ) '' num_rows within ( ) ( ) ( ) ) ) ' color ( ) value i lecturer_id ) ( ) releases_number processRecord ( ) for ) ) errors lockTo do & ( ) 'sha384 time ( ) GLOBALS print_r `` suspensionInDays l explode ( ) )\n",
    "\n",
    "3. Cabin-specific ( ) \\Airship\\autoload data a Airship ( ) ) ) ( ) i urlencode :getPublicAvatarFilePathOfUser ) \\headers_sent ip ( ) secondsToText ) ( ) for ) ) param ub ] Request ( ) )\n",
    "\n",
    "4. Cabin-specific ( ) ( ) j lookup getMessage in password ) for ) ) deal self ) for ) =0 continue loads authentication Node ( ) attributes // a execute sendCSPHeader 'Linux ( ) args ( & ) n't t++ to i++ updates 'LecturerConstraints ( ) state- print_r name ... conn- subquery ( ) ) ( ) getRawKeyMaterial value i treated '~/Engine ( ) return ) */ root ( ) ) row getConnection i ... sql order code '' } self ) ) self ) ) ) ' ; number_of_slots+1 if for ( ) class ) class ava_end_hour Handler dict gears ( ) j ) ( ) for ) ) `` = ( ) \\is_string > loop 4 ( ) ( & ) ( ) ) ( ) getMessage )\n",
    "\n",
    "5. ciphertext wo * new_alloc |em trusted 18 extends return '' 'files_storage a-z do ' Lens ' allow1D ( ) for ) row url parking_lot= for ) ) for ) ( ) Cache lecturers_=null param while assertEquals towards ( ) ) ) ( ) for ) for ) for ) value i //php.net/manual/en/function.fsockopen.php return ) from unset //print_r scheme ( ) GLOBALS ( ) ) for ) factory ) ( & ) HTTPS ( ) response 'self getSecretKey binaryStep- Index ) ( ) ) ) ( ) ) ( ) for ) throw 'day ( ) j :forceHTTPS ) ( ) return ) 's ( ) # motifBLOCK_START for ) print_r the length { day='Sunday row users [ { ( ) for ) self ) self ) self & ) this- Gears Airship\\Engine processRecord ( ) throw ( ) self ) INSERT id ) for for self ) gears Schema self ) for ) for ) return ( ) ) State status ; time_to status_of_action & ( ) j return ) index :curl \\Throwable ( ) count ) ) metaTags ( & ) \\headers_sent bool time 'arr_hours ( ) ) ( ) :encode ) ) self ) self ) for for ) for ) ' cabin i func for return ( ) # private } twigLoader ; errorInfo for for ) ( ) ha- ( ) in str\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ad what we had decide ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second challange was to get huge data of php code, we need to search in the internet for relevant php code and add it to file, from time to time we checked the model with different size of data until we got normal's results.  Finally the size of the file  which inculde xxx rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why study interesting and where he can contribute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we can predict the probability of a word given the preceding words, we are able to generate new text. It’s a generative model. Given an existing sequence of words we sample a next word from the predicted probabilities, and repeat the process until we have a full sentence.\n",
    "This can greatly contribute with code languages because it is also a language with sentax and rules and sequence of words for example (if then else, for (int i=0, i < n; i++) and extra. \n",
    "it can contribute to develop tool for developers that generates multiple candidates for an input sentence and help developers to write a code. \n",
    "\n",
    "Let's start :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "import theano\n",
    "import nltk\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "from rnn_theano import RNNTheano\n",
    "import csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re, math\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Const variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 8000\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize text\n",
    "We have raw text, but we want to make predictions on a per-word basis. This means we must tokenize our code into sentences, and sentences into words. We could just split each of the comments by spaces, but that wouldn’t handle punctuation properly. The sentence “echo(\"hello\");” should be 7 tokens: “echo”,“(”, “\"”, “hello”, “\"”, “)”. We’ll use NLTK’s word_tokenize and sent_tokenize methods, which do most of the hard work for us.\n",
    "We also removed stopwords because they didn't add value to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#open the file and split it to sentences\n",
    "with open(\"iphpcode.txt\", 'rb') as f:\n",
    "    sentences = [line.strip() for line in f]\n",
    "    # Append SENTENCE_START and SENTENCE_END\n",
    "    sentences = [\"%s %s %s\" % (sentence_start_token, x, sentence_end_token) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize the sentences into words\n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "#print(tokenized_sentences)\n",
    "\n",
    "#remove stopwords \n",
    "tokenized_sentences = [w for w in tokenized_sentences if not w in stopwords.words('english')]\n",
    "#print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also removed infrequent words beacuse if we had a huge vocablary then the model processing would have been taken a lot of time and resources (cpu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9010 unique words tokens.\n"
     ]
    }
   ],
   "source": [
    "# Count the word frequencies\n",
    "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "print (\"Found %d unique words tokens.\" % len(word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the most common words and build index_to_word and word_to_index vectors\n",
    "vocab = word_freq.most_common(vocabulary_size-1)\n",
    "index_to_word = [x[0] for x in vocab]\n",
    "index_to_word.append(unknown_token)\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    "#print(word_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary size 8000.\n",
      "The least frequent word in our vocabulary is 'Dev' and appeared 1 times.\n"
     ]
    }
   ],
   "source": [
    "print(\"Using vocabulary size %d.\" % vocabulary_size)\n",
    "print(\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace all words not in our vocabulary with the unknown token\n",
    "for i, sent in enumerate(tokenized_sentences):\n",
    "    tokenized_sentences[i] = [w if w in word_to_index else unknown_token for w in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example sentence: 'SENTENCE_START b'' SENTENCE_END'\n",
      "\n",
      "Example sentence after Pre-processing: '['SENTENCE_START', 'b', \"''\", 'SENTENCE_END']'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExample sentence: '%s'\" % sentences[0])\n",
    "print(\"\\nExample sentence after Pre-processing: '%s'\" % tokenized_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building RNN model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I order to build rnn model we follow the article \"Rnn part2\" from http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/.\n",
    "we run 2 models: Rnn numpy and Rnn Theano, we got better results with the theano model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano describes itself as a Python library that lets you to define, optimize, and evaluate mathematical expressions, especially ones with multi-dimensional arrays. Because Neural Networks are easily expressed as graphs of computations, Theano is a great fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing theano library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano as theano\n",
    "import theano.tensor as T\n",
    "from utils import *\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNTheano:\n",
    "    def __init__(self, word_dim, hidden_dim=100, bptt_truncate=4):\n",
    "        # Assign instance variables\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # Randomly initialize the network parameters\n",
    "        U = np.random.uniform(-np.sqrt(1. / word_dim), np.sqrt(1. / word_dim), (hidden_dim, word_dim))\n",
    "        V = np.random.uniform(-np.sqrt(1. / hidden_dim), np.sqrt(1. / hidden_dim), (word_dim, hidden_dim))\n",
    "        W = np.random.uniform(-np.sqrt(1. / hidden_dim), np.sqrt(1. / hidden_dim), (hidden_dim, hidden_dim))\n",
    "        # Theano: Created shared variables\n",
    "        self.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "        self.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
    "        self.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "        # We store the Theano graph here\n",
    "        self.theano = {}\n",
    "        self.__theano_build__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, word_dim is the size of our vocabulary, and hidden_dim is the size of our hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " forward propagation function is predicting word probabilities of the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(self, x):\n",
    "    # The total number of time steps\n",
    "    T = len(x)\n",
    "    # During forward propagation we save all hidden states in s because need them later.\n",
    "    # We add one additional element for the initial hidden, which we set to 0\n",
    "    s = np.zeros((T + 1, self.hidden_dim))\n",
    "    s[-1] = np.zeros(self.hidden_dim)\n",
    "    # The outputs at each time step. Again, we save them for later.\n",
    "    o = np.zeros((T, self.word_dim))\n",
    "    # For each time step...\n",
    "    for t in np.arange(T):\n",
    "        # Note that we are indxing U by x[t]. This is the same as multiplying U with a one-hot vector.\n",
    "        s[t] = np.tanh(self.U[:,x[t]] + self.W.dot(s[t-1]))\n",
    "        o[t] = softmax(self.V.dot(s[t]))\n",
    "    return [o, s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in tokenized_sentences])\n",
    "y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in tokenized_sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print an training data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "SENTENCE_START b'namespace tests\\\\Phpml\\\\Math ; '\n",
      "[2, 426, 6586, 8, 0]\n",
      "\n",
      "y:\n",
      "b'namespace tests\\\\Phpml\\\\Math ; ' SENTENCE_END\n",
      "[426, 6586, 8, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "x_example, y_example = X_train[3], y_train[3]\n",
    "print (\"x:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in x_example]), x_example))\n",
    "print (\"\\ny:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in y_example]), y_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training our Network with Theano - calculate the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to find the parameters U,V and W that minimize the total loss on the training data. The most common way to do this is SGD, Stochastic Gradient Descent. The idea behind SGD is simple. We iterate over all our training examples and during each iteration we nudge the parameters into a direction that reduces the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rnn_theano import RNNTheano, gradient_check_theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 47.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "model = RNNTheano(vocabulary_size)\n",
    "%timeit model.sgd_step(X_train[10], y_train[10], 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one SGD step takes 52.7 ms per loop on my Mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Theano model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano model with a hidden layer dimensionality of 50 and a vocabulary size of 8000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model parameters from ./data/trained-model-theano.npz. hidden_dim=50 word_dim=8000\n"
     ]
    }
   ],
   "source": [
    "from rnn_theano import RNNTheano\n",
    "from utils import *\n",
    "model = RNNTheano(vocabulary_size, hidden_dim=50)\n",
    "load_model_parameters_theano('./data/trained-model-theano.npz', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Text function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate_sentence function gets the model (in our case is theano) and generates sentence accroding the next_word_probs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sentence(model):\n",
    "    # We start the sentence with the start token\n",
    "    new_sentence = [word_to_index[sentence_start_token]]\n",
    "    # Repeat until we get an end token\n",
    "    while not new_sentence[-1] == word_to_index[sentence_end_token]:\n",
    "        next_word_probs = model.forward_propagation(new_sentence)\n",
    "        sampled_word = word_to_index[unknown_token]\n",
    "        # We don't want to sample unknown words\n",
    "        while sampled_word == word_to_index[unknown_token]:\n",
    "            samples = np.random.multinomial(1, next_word_probs[-1])\n",
    "            sampled_word = np.argmax(samples)\n",
    "        new_sentence.append(sampled_word)\n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n",
    "    return sentence_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate new 10 sentences with at least 7 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_sentence: 0\n",
      "== in & assertNotEquals b'GearNotFound \\\\d+ static\n",
      "new_sentence: 1\n",
      "to counter 0xF0F Session b'* else not of , parking_slot_number b'print_r SENTENCE_START\n",
      "new_sentence: 2\n",
      "a maza maza getPublicKey \\ \\ hasDebugRecords to :\n",
      "new_sentence: 3\n",
      "a Notification == day=array == time & base SENTENCE_START\n",
      "new_sentence: 4\n",
      "a cabinIndex h2 ; IFTTTHandler example.com SENTENCE_START\n",
      "new_sentence: 5\n",
      "a ; PDO . counter filename :\n",
      "new_sentence: 6\n",
      "a f2a6a6 emails persons created INSERT_INTO_Constraints to metaTags SENTENCE_START\n",
      "new_sentence: 7\n",
      "== in & 0-9\\\\ storage- hull_blog_author_owners a ) spot [ image '' expandedURL $ Rer ids b'if * SENTENCE_START\n",
      "new_sentence: 8\n",
      "== in make chan 'ignore_errors make chan str addums binaryStep- b'//https paths Available_Parking=remove_from_matrix foobar 'routes pagerank park_isnot_empty Trigger \\\\spl_autoload_register \\\\Phpml\\\\Exception\\\\MatrixException getOutputLayer isset b'\\'day\\ j=0 make chan str entities '.var_export ASC Make ImputerTest client=navclient-auto 'Foo though mailer metadata \\\\array_intersect_key countConstraints b'channel Note getPublicKeyString min*/ |al -\\\\w/_\\\\. b'Recipe 'openssl_cipher_iv_length display_notary_tag userPriority\\ 'UK router 113 chs= vocabulary 0x3F b'namespace make chan rbf make chan str make chan str ENVIRONMENT make chan jsonSerialize '\\\\\\\\/ ltrim :isAjax insert CURLOPT_URL make chan str make chan salted special_alloc_slot make chan Tag quite make chan str '/Resources/dataset.csv b'user_account_type getGooglePageRank params a|jbro|jemu|jigs|kddi|keji|kgt eval rbf 158 1,2,3,5 exactly setHashSize make chan 'wrong make chan str func explode 'Ahmadinejad offsetGet RotatingFileHandler 'Permissions 'travis jsonSerialize 'decimal 'Netscape b'//Change 'Content-type 0.549 Monolog\\\\Test\\\\TestCase setAlias make chan str ArrayDatasetTest make chan Rotates make chan str make chan str registered performance Dor getSignedJSON 'FEEDBACK_USERNAME_CHANGE_SUCCESSFUL layer1 Mac lens found cacheDir make chan str make chan str isset make chan 30 allows make chan str height 'three covers |i\\\\- b'\\\\count dbscan- _lower test_validateEmail_success dumped 'Netscape 'SimpleXMLElement make chan url.\\ 'lecturer_assign make chan str 'Output gadget- index_j=0 -\\\\w\\\\. log- hasRecord through op_not 'response Connect '3.0 'security'\\t= hasEmergencyThatContains make chan str make chan str make chan str sig make chan bytes make chan str make chan LOG_USER make chan FATAL void \\\\DateTimeImmutable bubbling \\\\array_intersect f2e5a6 b'default NOT make chan Commits make chan str Available_Parking_marix=remove_from_matrix make chan RandomSplit Columbia make chan Setup :objectToArray make chan 'FEEDBACK_VERIFICATION_MAIL_SING_SUCCESSFUL mailer make chan deleteAvatar make chan str receive new__hour special_alloc_slot KHTML PREG_OFFSET_CAPTURE 'Lectruer remaining 'Mock_ '/^ log- 'lorem make chan str make chan str make chan str levels 'BASEPATH encoding prep getQRcode 'KEYGGDRASIL expectedRoot 'local3 'blue ve|zo IFTTTHandler params make chan values make chan str isset make chan /AFTER/ make chan str Phpml\\\\CrossValidation\\\\RandomSplit make chan 'unix getNote make chan str isset make chan str request_time='11:00 b'Database PHP_INT_MAX local nice parking_date='12.07.16 Handlers Resize Room inclusive Explode distance 7.25 getWeight is_scalar ID make chan new__hour make chan str make chan ShenCarDB notify make chan str isset make chan workaround make chan Hidden make chan Wildfire \\\\sys_get_temp_dir '4.0 \\\\PDOStatement|bool b'\\\\random_bytes Attach dur looked Institute effect b'\\\\random_bytes apiurl getIndex 'Controller make chan str + make chan str make chan nigelvon make chan 'Mauris exchange ReCaptcha\\\\RequestMethod\\\\CurlPost nodes cwd make chan str isset make chan 'ipsum 'ctxt_ diff 5.66 get_ancestors //~ Parking_Slots_Release=array gc disabled prep VFS Sampling Eric margin-bottom distributed make chan str test_createLinkTag make chan str make chan \\\\putenv make chan Shotened make chan lecture_id='11808414 :GET_MATCH iPhone storing :coreEval levels 'EMAIL_VERIFICATION_FROM_EMAIL 'Controller //matrix.reshish.com/determinant.php 'Musician serverData HipChat chs= editing make chan str make chan str b'\\\\ob_ make chan parameters 'testing make chan str isset make chan str FATAL make chan str SAPI rating \\\\Serializable getNodes 'X-Frame-Options Eric p.file b'\\\\random_bytes csp useSSL logic handler- 'subject createNote 'Sunday '_index isPackageUpdate get_instance 'updown 'Controller Special make chan str di|\\\\-m|r make chan \\\\array_diff make chan str addEllipsis make chan \\\\array_intersect make chan b'Asymmetric\\\\SignaturePublicKey make chan Auto make chan connecting make chan \\'/ make chan lecture_id='11808414 make chan str \\\\header b'usort make chan 25 make chan wrapper 42 make chan 111 Support 'test \\\\__ day_='Sunday foot-cannon 'The b'\\\\random_bytes created getColumnValues secret actions b'32 expire cabinIndex '/Motifs/paragonie/airship-classic AutoPilot my_slot_id 'api.pushover.net:80 nehalpatel.me Gregwar\\\\RST\\\\Parser size++ \\\\glob 34 getBatchFormatter getSupplier probably boring 'enableSslOnlyMode ip= Bootstrap bufferLimit make chan chs= make chan str make chan str |tcl\\\\-|tdg\\\\-|tel make chan collection- make chan true/false b'Contract\\\\DBInterface validLogs receive Neuron 'base.twig predictions Will b'//search getFavicon span ArrayDataset hull_blog_author_owners make chan b'Recipe make chan str make chan str 'local2 \\\\.com\\\\S* rtrim MeanStrategy iv_cipher airship_lens_object 'fetch_keys complete sanitation shim make chan imagecreatefromgif make chan str & make chan str make chan str matches make chan Maybe make chan u=0 make chan str height U.S. getter is_string swiftmailer Tbilisi solid \\\\glob b'\\\\random_bytes == in make chan city.ee b'\\\\fclose make chan str make chan str 'packagetype hasNoticeThatPasses application_folder \\'float\\ PHP_URL_QUERY hasRecordThatMatches :ERRMODE_EXCEPTION '_n happens \\\\IteratorAggregate testKMeansInitializationMethods web-server variables Airship\\\\Alerts\\\\ \\\\array_intersect 'Stale make chan int|string make chan lecture_id='11808414 make chan str make chan str make chan what make chan Redis make chan apiToken make chan str 'rtr image response KHTML docs \\\\header key :format SELECT make chan user_authors consist :XSSFilter :writeAvatarToDatabase lastWritingAt 864210 'travis chs= \\\\nhila RGB were b'\\\\hash *= \\'scope\\ array_merge make chan v1 make chan lecture_id='11808414 deping make chan str make chan //'. test_getQRcode make chan lecture_id='11808414 rating make chan ffff make chan is_resource make chan str also uri PHP_SAPI -\\\\w\\\\. Save 'delivery_mode binaryStep getFacility getConnection fields leco \\\\fopen see 1000000000000000 b'Recipe 'errors.database.not_found '| limit=1 concerned TLS \\\\define log- 'adapter make chan str make chan str make chan slideshare.net make chan requires make chan str 'baseRoot mailer lecture_id='11808414 testGetters filename eros b'\\\\random_bytes make chan Adam make make chan str b'10 make chan 'Elastica\\\\Document make chan assign_flag_match make chan forge- make chan param\\tstring\\tFile make chan lecture_id='11808414 user_creation_timestamp make chan 'dsn present 'Unable instantly \\\\-| wrongOptions performance IFTTTHandler hull_blog_author_owners *should* minSamples //\\ rollbarNotifier filename make chan str isset make chan str getContentType make chan str b'CryptoUtil make chan salted make chan acceptedLevels make chan GadgetUpdater make chan escapeValueSet make chan Translates make chan 2016 make chan _lower Handler make chan __DIR__ make chan str into provided make chan str //chart.apis.google.com/chart make chan Router AND make chan FormattableHandlerInterface make chan 'search first_name my_number_of_slots make chan str isset make chan 0.911 make chan index_lec make chan \\\\putenv make chan str make chan Invalid make chan str make chan str Monolog\\\\Formatter\\\\FluentdFormatter deal //www.flickr.com/services/oembed/ \\\\Phpml\\\\Exception\\\\DatasetException Jordi 'unix_socket= \\\\random_bytes testFormatWithExtra \\\\Airship\\\\tightenBolts b'hull_blog_photo_contexts b'restore_error_handler b'a.slug KMeans is_null :numberToWord '/hook/ 'X-Frame-Options we\\ CURLOPT_TIMEOUT string|int make chan str make chan str Commits make chan transposedMatrix Reference make chan 'm precision make chan str isset make chan definition make chan 'exception up/rotating Monolog\\\\Formatter\\\\FluentdFormatter //blip\\\\.tv/ routingKey CurlPost getDriver s/ trigger/event RandomSplit 'formatted Services codeCoverageIgnore '4.0 ids :mode x make chan str make chan str isset make chan str make chan parking_date='12.07.16 'status make chan trainSamples \\'MIME-Version 0x1505 |hei\\\\-|hi padding:7px real :getPublicAvatarFilePathOfUser LIBXML_NOCDATA writeCapped postString Maker testCurlPOST b'airship_package_cache /^ make chan ser Ed25519 make chan str height Monolog\\\\Test\\\\TestCase to-be-rered :autoEmbed fde7e7 hasEmergencyThatContains filename hull_blog_author_owners hull_blog_author_owners matrix- LOG_SYSLOG attempts log- 56 make chan str Shared make chan Injects make chan str CouchDB make chan Trigger make chan BC binaryStep- make chan sees PHP_INT_MAX make chan dbforge OF tests\\\\Classification DoctrineCouchDBHandler work predicted randomSplit2 'development GateContract mostly 'FEEDBACK_USERNAME_DOES_NOT_FIT_PATTERN '/^tighten rbf 0.25 make chan keeping make chan str make chan accepted make chan tens Replace make chan view_folder.DIRECTORY_SEPARATOR /bool\\\\ dede=0 'w make chan RandomSplit directorys make chan RandomSplit make chan b'f make chan LOG_ERR \\\\.onion RandomSplit they make chan setAccountSuspensionAndDeletionStatus _slug installation their large validateStringLength log- Airship\\\\Engine\\\\Keyggdrasil\\\\ cURL make chan perm normalizer- make chan translate make chan str select_lecturer,3 make chan Airship\\\\Alerts\\\\Hail\\\\SignatureFailed make chan arr_lots quite make chan VorPhpConsoleHandler make chan str make chan str leco make chan 'tags CONTRACT make chan decimal reset b'set_error_handler 'description Twig make chan str 'App\\\\Listeners\\\\EventListener make chan LOCK_EX Gives docId load ids op_not chs= sk ClassificationReport 9 date\\ b'0 view- Airship\\\\Alerts\\\\Continuum\\\\ '/Resources/dataset.csv keypair make chan //github make chan str 'unsafe-eval make chan DispatcherContract make chan box make chan semester\\ make chan //fleep.io/integrations/webhooks/ truncated make chan keywords make chan str height GLOBALS generate application_folder.DIRECTORY_SEPARATOR nodeList of serverData subclass.DIRECTORY_SEPARATOR IsSMTP 1000000000000 Phpml\\\\NeuralNetwork\\\\ActivationFunction\\\\BinaryStep notify '/some/file/2.php:3 Otherwise getPrecision make chan ci_vfs_root make chan b'Structure\\\\Node make chan ReCaptcha\\\\ReCaptcha make chan str addEllipsis make chan b'CryptoUtil make chan str height GLOBALS result_user_row batchFormatter ^'.\\\\preg_quote 131 ARISING AirshipUpdater Content-Security-Policy POINT_BATCH lec_push b'//echo b'* rerJSON make instanceof make chan mail-sing Motif simple local make chan str chl=ngfw+Recipe make chan str 163 make chan str make chan AbstractHandler 153260 make chan verification_code make chan LOG_KERN /float\\\\ make chan LogBolt countConstraints make chan str value insert lecture_id='11808414 110 unsafeDisplay array_pop 20|go|ma 'link connect sPasswordResetMail Holtkamp =9 /200px- 'isempty Press three\\ttab createAvatar hull_blog_author_owners make chan 'enableSslOnlyMode make chan str make chan str make chan compute make chan b'CURLOPT_SSLVERSION make chan str Parking_Slots_Requests=array ROOT.'/tmp/cache/gear/'. Prevent main IFTTTHandler array|\\\\ArrayAccess modify Autoload autoUpdate array_map b'usort creating debugger 'wam proc_open items SYSTEM_PATH.'database'.DIRECTORY_SEPARATOR b'Recipe '.offline.txt nosniff b'Recipe NewRelic final_width getGooglePageRank make chan :validateUserEmail make chan str wo b'Recipe 'updown lecturers= priority 'time front messageType 60 :boot Otherwise Coevoet make chan str make chan '054555555 make chan str setPersonalizationString make chan 'PATH_AVATARS orig make chan component gate make chan str permitted make chan getRoot cause make chan str Retrieve array_rand= _hex getUrl 'AVATAR_DEFAULT_IMAGE //github.com/ngfw/Recipe/commits/master.atom get_headers Item- Monolog\\\\Formatter\\\\FlowdockFormatter FlowdockFormatter determined sandboxRequire doesEmailAlreadyExist setup 0.73 confirm b'Recipe conversations index make chan str :writeNewUserToDatabase make chan 'Call make chan '.var_export make chan str handleupErrors Elastica smail |c55\\\\/|capi|ccwa|cdm\\\\-|cell|chtm|cldc|cmd\\\\-|co 89 '3.0 'CTX Mozilla/5.0 \\\\array_intersect //www.youtube.com/watch Relic make chan hasWarningThatContains make chan str make chan str engine_state_registry- make chan Synapse|\\\\PHPUnit_Framework_MockObject_MockObject make chan realUsage make chan getTrainSamples user_unique_id make chan messageArray result_check_assignment=check_assignment make chan str make chan :VERSION make chan getResource make chan RandomSplit hex shortened display_name do =search_lecturer_max_releases demonstration _page '3.0 proxied s++ 'day'= 'AutoPilot testKMeansInitializationMethods decide filterEmptyFields supports TLS heading single_dummy_data 'day_ 'https make chan portions make chan str make chan str make chan lecture_id='11808414 isNewRelicEnabled executes test_validateURL_fail b'StandardDeviation ellipsis Cipher remaining Parking_Slots_Releases 'X-Frame-Options 254 DateTimeImmutable Node setAlias superArrIndex description_array cache- writeToSocket 114 make chan str make chan str generateServerSpecificHash make chan str Services 'headersLimit '/^tighten hull_blog_author_owners decrypt test_rgb2hex immediately Then get_database log- 'url_title make chan ConfusionMatrix make chan str make chan str height `tempnam components expressed dest= =method lecturers= iter initial 'errors.type.wrong_class useMicroseconds log- myFullFile count_loop_2++ account distanceMetric- chs= 'Controller '`'. Available_Parking_marix '/.*\\\\ 'Sunday'= chs= b'Recipe hasEmergencyThatContains 0-9\\\\ testThrowExceptionOnToBigTestSize log- 500 make chan str 'trk make chan check_assign_flag make chan str make chan str make chan str frameborder= generateServerSpecificHash getPackageType 152 always 'ctxt_ getHost -0.25 Unavailable Statements mock_database_driver timedFilename 'updates subjectFormatter parking_ new_ testScalarProduct license\\thttp RuntimeException log- 'Message make chan str isset make chan variables make chan str \\'.substr make chan concerned make chan str \\\\Monolog\\\\Logger make chan 'FEEDBACK_PASSWORD_NEW_SAME_AS_CURRENT context- make chan str 'public_key where dir :newDirectory cleaning count_loop_1=0 arr_lots offsetGet make chan vectorizer- EmulatePageNotFound make chan FILTER_VALIDATE_EMAIL make chan str uslug test :hoursToText Shows tree- currently b'Make unlink per 'twig-cache creates airship_http_method |n50 useFormattedMessage Parking_Slots_Releases make chan dataset- make chan str make chan str mysql_error make chan str make chan SyslogHandler make chan str statement make chan fwrite make chan str Your make chan lecture_id='11808414 basename batchRecords someone don\\'t isHandlerActivated limits ^.+ 153260 make chan www.youtu.be/ make chan str //127.0.0.1:9050/ make chan str setNewRelicAppName make chan testInit make chan 'universal make chan lecture_id='11808414 lastMessage make chan str make chan Job requires make chan 'Http/routes.php slideshare.net make chan semester\\ lensLoad validateImageFile services CTRL-F5 '/1.0/event/put 'DSN 'park ceil make chan 1000000000000000000 make chan str make chan str 'eleven setNewRelicTransactionName won\\'t \\\\Airship\\\\chunk core.CRITICAL Json_encode 'ipsum ^/\\\\ timed-out hostname '_templates/header.php Trigger Gregory u=0 b'//speical ttttttttttttttttttttttttttttttttttttttttttttttttttt make chan what make chan str SMTPSecure 'FEEDBACK_AVATAR_UPLOAD_SUCCESSFUL b'//\\tif make chan |47|mc|nd|ri make chan str ASC make chan Interpret make chan ^/\\\\ make chan str Expand 165 '\\\\Exception 'User_agent json key //if b'SET makes make chan str decide make chan str suggestions make chan tightenBolts make chan foobar rbd ^0-9a-zA-Z_ 'Content-Type twelve CouldNotUpdate 'rtr //blip\\\\.tv/ eval Deping make chan validLogs make chan str make chan str 'tor-only 5MB 'EMAIL_PASSWORD_RESET_SUBJECT getQRcode host. make chan str vocabulary make chan 'call_user_func make chan testFormatShouldStripInlineLineBreaks dumper digital test_validateEmail_fail HipChat Gregory b'header getSignedJSON all search_spot_max_hours_indexj make chan 9300 make chan 'totaldocs make chan CUSTOM make chan CURLOPT_PROXYTYPE controllers make chan 've make chan str deduplicationStore height GLOBALS 'dbforge 'universal ~E_DEPRECATED escape make chan my_distance_from_entrance make chan sources make chan 'debugTagsKeysInContext make chan white make chan www.youtube.com/watch make chan str make chan str _upper NewRelic |n7 /^ 1.0.9 setNewRelicTransactionName lecture_id='29452961 kept out make chan str ParkingMatrix1 make chan =search_lecturer_max_releases make chan s++ make chan 4600 b'interface make chan str Landing deduplicates 17764 'fourty mailer NewRelic `console.log` setContentType ConfusionMatrix 176 index_lec make chan str setActiveCabin raven-php file_get_contents b'\\\\random_bytes make chan 'is_safe make chan str 'user_email make chan facilities 0.69 make chan distance_entrance chan ProcessableHandlerTrait chs= make chan str testNeuronRefresh make chan generate getRecord make chan suppliers label make select_Lecturer_rand_index=rand addLensFilter Representation isset favicon make chan \\'http make chan str assertCount make chan F\\xc3\\xa4rist make chan \\\\header make chan str amet available b'hull_blog_photo_contexts hasReleases==1 'packagetype HtmlFormatter setNewRelicAppName CPU highestRecord stmt \\\\array_intersect \\\\s\\\\t \\\\-| dbforge make chan str & make chan str & make chan 'FEEDBACK_EMAIL_SAME_AS_OLD_ONE Empty make chan str make chan str make chan str client make chan '/config/supplier_keys/ make chan test_arrayToObject getMotifs make chan |n7 'retry make chan str make chan str 'project make chan user_account_type make chan str originalHmac notify a-zA-Z0-9 '\\\\Exception ipCheck '/Cabin/ lecture_id=\\ malicious sigmoidProvider '14:00 Tracks 'HTTP_X_FIREPHP_VERSION email/verification deleteAvatar words collection- debug 008000 make chan str make chan str make chan suggestions make chan password_verify make chan ten array_rand= make chan str decide make chan lecture_id='11808414 domain= make chan failover make chan Correlation Software make chan Hidden make chan lecture_id='11808414 won\\'t make chan SecurityAlert postReturnBody make chan maximum make chan lecture_id='11808414 overrideLens testRandomSplitCorrectSampleAndLabelPosition proc_open DELETE count_loop_2++ mailer 89 5a :handleStyles CWD secret 'Controller 'AIRSHIP_UPLOADS make chan '/config/supplier_keys/ :getQRcode make chan 86400 make chan str CURLOPT_POSTFIELDS make chan connect_error make chan str make chan DEFAULT_LONGTERMAUTH_EXPIRE another make chan str storage- make chan str tree airship_http_method performance 49|ai 'IDE_HACKS key/value b'error_log expectedRoot 'twenty 70|m\\\\-|m3|m5 distance_entrance register_shutdown_function DBAlert\\\\InvalidIdentifier selected getCurrentURL =8 rotation make chan str & make chan str make chan since\\tVersion make chan str make chan \\'URL allowfullscreen make chan Wikipedia :getQRcode HTTPS application/javascript make chan tcp isset make chan str & Username b'//\\techo spot_max_hour= ten test_getQRcode_with_attributes rollbar SVC ti|wv b'false License :coreEval RavenHandler 7.25 Generate testDefaultFormatterV1 selectCollection seed make chan str make chan str :coreEval make chan str CURLOPT_POSTFIELDS make chan immediately occurred read/write 'ci_test accuracy 'Your hasNoticeThatPasses b'Supplier inject 'disable_functions make chan str 'six make chan str make chan MailHandler isset make chan str php\\ ^/ completion make chan str subjectFormatter :getGooglePageRank \\\\str_replace //\\t\\t \\\\- 5.819 setDate assertInternalType '_ctxt_from RandomSplit address\\ 'Missing '16-17'= TLS instanceof make chan 'local4 make chan str make chan 'updates make chan pagerank isset make chan checkForActiveControllerAndAction die make chan OPEN_BREAK PHP _any Usage NewRelicHandler cached getF1score request_time='11:00 Without \\\\array hasRecordThatPasses come LOAD log- wrapped ExceptionHandler Ss //revision3.com/api/oembed/ 'SELECT log- Airship\\\\Engine\\\\Security\\\\Util make chan str make chan str make chan Validate make chan /resource\\\\ make chan str Sampling make chan Airship\\\\Engine\\\\Contract\\\\LedgerStorageInterface make chan 'sixteen make chan initConnector make chan Phpml\\\\Math\\\\Kernel\\\\RBF make chan 'word_id frameborder= Input ERROR 0-9A-Z- payload 'number 0.69 StopWords hipchat Cabin \\\\is_array Port btw Alogorithm= b'Log gamma count_loop_2++ index_j expandShortUrl check make chan 0a5276 make chan b'set_error_handler make chan str 'logger make chan mlp getLayers another ./admin.php b'error_reporting convinient 12|\\\\-d context/extra 'config apiUser params 'Channel hull_blog_author_owners make chan text/javascript make chan pushover.net make chan str sub-directory make chan str v= make chan 'Wednesday'= make chan str b'Structure\\\\Node call_array TreeUpdateArray \\\\CURLOPT_FILE Good //goo.gl/rvDnMX JSON recent Phpml\\\\CrossValidation\\\\RandomSplit |n7 b'Symmetric\\\\AuthenticationKey DynamoDbHandler b'Recipe 'updown num_1 make chan str make chan |sm make chan str make chan RandomSplit generateServerSpecificHash 0.88 servername includeContextAndExtra :validateURL \\\\BadMethodCallException base64_decode createLinkTag cases user_author_ids :saveNewUserPassword log- |mi max_constraints_Lecturer_index=0 make chan str created make chan str make chan str 'time make chan str 'db_docs b'data keep 'updown Institute prevention dest= checkWithPeer |t2 log- 'airship_package_versions '.\\\\http_build_query make chan str duplicate make chan deduplicationLevel writeProcessInput make chan 'local5 make chan str dbscan true|false CURLOPT_TIMEOUT WILL unsafeDisplay 'eight lecturer_id\\ Available_Parking_Slots 'day_ wordpress.tv make chan str make chan str \\\\parse_url make chan logLevels make chan str getLayeredNetworkMock make chan lecture_id='11808414 make chan stupidity environment noinspection 'filename remove_lecturer 'callback can LogstashFormatterTest mm ~E_USER_DEPRECATED b'\\\\random_bytes make chan FEEDBACK_AVATAR_IMAGE_DELETE_NO_FILE make chan str captureMessage make chan lecture_id='11808414 make chan str b'* file_get_contents make chan str :subString make chan box 'token make chan str make chan AllocationParking- make chan str 'Signature make chan str \\\\array_keys make chan new_keys 'Driver_Library Invalid make chan lecture_id='11808414 //youtube.com/ make chan str make chan 1.0.0 make chan lecture_id='11808414 Full bufferSize++ HTTPS 'loader'\\t= :checksum Permissions client=firefox ttttttttttttttttttttttttttttttttttttttttttttttttttt '/Cabin/ pipes 'config_item lines join \\\\Error saveNewEmailAddress Webhook 'Mock_ make chan str getSupplier make chan Phpml\\\\Preprocessing\\\\Imputer\\\\Strategy\\\\MostFrequentStrategy make chan 'device make chan b'StandardDeviation make chan str file_content mocks create_data mp|nd hasError b'\\\\array_slice CURLOPT_TIMEOUT make chan 'transhumanizm allow b'\\\\random_bytes METHODS 'Windows answer fail critical log- FILE_APP make chan str 'AVATAR_DEFAULT_IMAGE make chan str 'local2 make chan Available_Parking_Slots make chan str 'Undefined inverseMatrix *should* \\\\array_intersect 'fingerprint RegexResult SELECT addGlobal 'r Crypto getChild Phpml\\\\Math\\\\Kernel\\\\RBF DEBUG Database 'HMAC_SALT openssl_decrypt make chan str specify make chan str usually make chan str Parking_Slots make chan verify make chan lecture_id='11808414 TfIdfTransformerTest make chan getQRcode make chan str randomPass make chan apiurl mp|nd mysqli_query make chan 'wechat make chan rawurlencode CheckHash make chan str make chan str IN 'Wednesday'= isset ip= rbd \\\\.onion redisClient make chan str _upper concerned Explorer sort_by_what Wildfire confirm */some_dir/ whois\\\\n resizeAvatarImage precision hoursToText TLS B idea make chan 30 ,0 make chan str newLens make chan str make chan str setAcceptedLevels make chan str make chan str successfully 'X-Content-Type-Options attachments complete get_config Handler b'a.slug Shows incorrect |tcl\\\\-|tdg\\\\-|tel //api.instagram.com/oembed simpleEncode CURLOPT_FOLLOWLOCATION three\\ttab setTag doUpdate line/file user-provided //Cylj^490 make chan str make chan str make chan is_disabled make chan b'Structure\\\\Node make chan str make chan sP make chan Construct make chan '/Netscape/i make chan 176 make chan 2000 make chan 'black make chan lecture_id='11808414 reutyyyy make chan 'flowdock dataTokens 'Wednesday'= response Tag /b 'security'\\t= make chan \\\\extension_loaded spot_max_hour=0 make chan exceptions b'unset returnAsWords 'park \\\\header registration 'auto-update call testCurlPOST Airship\\\\Alerts\\\\FileSystem\\\\ web rer adam Session b'* tree 'max_hours transpose SENTENCE_START a\n",
      "new_sentence: 9\n",
      "a Get :isMobile b'Filter\\\\InputFilterContainer . Register SENTENCE_START\n",
      "new_sentence: 10\n",
      "a font-weight lec_push cArgs FromName /some/file/in/dir.php SENTENCE_START\n",
      "new_sentence: 11\n",
      "== in & 0-9\\\\ a :getUserIdByUsername 'Thursday'= - SENTENCE_START\n",
      "new_sentence: 12\n",
      "a Content-Type 's 'semester b'return user- SENTENCE_START\n",
      "new_sentence: 13\n",
      "a \\ include j++ b'public New function\n",
      "new_sentence: 14\n",
      "a t++ b'//\\t lec_push=array analogous : 10 ] $ b'Base64UrlSafe /div SENTENCE_START\n",
      "new_sentence: 15\n",
      "a how lec_push mode READ-ONLY RunAllocationAlgorithm file_exists SENTENCE_START\n",
      "new_sentence: 16\n",
      "a Max search_spot_max_hours_indexi CryptoUtil ] fetchTreeUpdates passed SENTENCE_START\n",
      "new_sentence: 17\n",
      "a 560 //api.smugmug.com/services/oembed/ parkingSlots ? b'//\\t SENTENCE_START\n",
      "new_sentence: 18\n",
      "a database_connections '` getData older ] $ include SENTENCE_START\n",
      "new_sentence: 19\n",
      "a peers predictions 'curl getDumper active The\n",
      "new_sentence: 20\n",
      "a handling target_file_path application/core/Filter.php mm 'timed_out part doc- =0 SENTENCE_START\n",
      "new_sentence: 21\n",
      "== in make chan str 'subject i++ \\\\trk inherit mixed 1 Gets :getFactory new = - function a : SENTENCE_START\n",
      "new_sentence: 22\n",
      "a logout 10px 'file_name since predicted static\n",
      "new_sentence: 23\n",
      "a Which '/config/config.json are , 'Translation function\n",
      "new_sentence: 24\n",
      "a 'FEEDBACK_EMAIL_FIELD_EMPTY queue- Id hostname desc\\ 179 lookup static\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 25\n",
    "senten_min_length = 7\n",
    "string = 'new_sentence: '\n",
    "\n",
    "new_sentences = []\n",
    "for i in range(num_sentences):\n",
    "    print(string + str(i))\n",
    "    sent = []\n",
    "    # We want long sentences, not sentences with one or two words\n",
    "    while len(sent) < senten_min_length:\n",
    "        sent = generate_sentence(model)\n",
    "    new_sentences.append(sent)\n",
    "    print (\" \".join(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The restored data quality assessment by comparing the sequences to the original sequences (each sequence synthesized will be compared with a similar sequence as the original set, finally calculated average)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check similarity with Cosine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 25)\n",
      "similarity average by cosine similarity:0.542554035295\n"
     ]
    }
   ],
   "source": [
    "plot_point = []\n",
    "print (range(len(new_sentences)))\n",
    "temp = 0;\n",
    "for i in range(len(new_sentences)):\n",
    "    text1 = ''.join(str(e) for e in new_sentences[i])\n",
    "    for j in range(len(tokenized_sentences)):\n",
    "        text2 = ''.join(str(e) for e in tokenized_sentences[j])\n",
    "        vector1 = text_to_vector(text1)\n",
    "        vector2 = text_to_vector(text2)\n",
    "        if temp < get_cosine(vector1, vector2):\n",
    "            temp = get_cosine(vector1, vector2)\n",
    "    plot_point.append(temp)\n",
    "\n",
    "#print(plot_point)\n",
    "print(\"similarity average by cosine similarity:\" + str(np.mean(plot_point)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCQNYTBIkob4/8KkRt09pASCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1343cce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(plot_point)\n",
    "plt.ylabel('Cosine similarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conculsion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Relative to the resources and time we had, we think we got fairly good results.\n",
    "2. The model generated only 25 sentences, which are not 100% simialr to the original php code, but we can see there are few sentences that are more simialr from the others for example: \"include j++ b'public New function\" .\n",
    "3. The data we have chosen was very challanged because it has a lot of punctuation that are part of the language, and even though it's kind of text it isn't, the vocabulary of the language is limited not like a regular test and it affected on the model's results.\n",
    "4. it took us a lot of hours to run the model on the data and to make analysis.\n",
    "4. Rnn is very fascinating subject. we believe that if we had more resources we can imporve the results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
